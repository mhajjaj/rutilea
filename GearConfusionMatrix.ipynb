{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Simulated predictions and targets (replace with actual data)\n",
    "# predictions = torch.tensor([0, 1, 2, 0, 2, 1])\n",
    "# targets = torch.tensor([0, 1, 2, 1, 2, 0])\n",
    "\n",
    "# # Calculate the multiclass confusion matrix\n",
    "# confusion_matrix = torch.zeros(3, 3)\n",
    "\n",
    "# for t, p in zip(targets, predictions):\n",
    "#     confusion_matrix[t, p] += 1\n",
    "\n",
    "# # Print the confusion matrix\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from super_gradients.training import Trainer, models\n",
    "from super_gradients.training.dataloaders.dataloaders import (\n",
    "    coco_detection_yolo_format_train, coco_detection_yolo_format_val\n",
    ")\n",
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import (\n",
    "    PPYoloEPostPredictionCallback\n",
    ")\n",
    "\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    #trainer params\n",
    "    HOME = os.getcwd()\n",
    "\n",
    "    CHECKPOINT_DIR = f'{HOME}\\checkpoint\\AGI-Dataset' #specify the path you want to save checkpoints to\n",
    "    EXPERIMENT_NAME = 'AGIExperiment' \n",
    "\n",
    "    ##dataset params\n",
    "    DATA_DIR = f'{HOME}\\GearInspection-Dataset3\\CategoryNG\\ClassAll' \n",
    "    LOGS = f'{CHECKPOINT_DIR}\\AGILogs'\n",
    "\n",
    "    # CATEGORY = 'CategoryNG\\ClassAll'\n",
    "\n",
    "    TRAIN_IMAGES_DIR = 'train\\images' \n",
    "    TRAIN_LABELS_DIR = 'train\\labels' \n",
    "\n",
    "    VAL_IMAGES_DIR = 'valid\\images'\n",
    "    VAL_LABELS_DIR = 'valid\\labels' \n",
    "\n",
    "    TEST_IMAGES_DIR = 'test\\images' \n",
    "    TEST_LABELS_DIR = 'test\\labels'\n",
    "\n",
    "    #what class names do you have\n",
    "    CLASSES = ['akkon', 'dakon', 'kizu', 'hakkon', 'kuromoyou', 'mizunokori', 'senkizu', 'yogore']\n",
    "\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "    DATALOADER_PARAMS={\n",
    "    'batch_size':64,\n",
    "    'num_workers':2\n",
    "    }\n",
    "\n",
    "    EPOCHS = 1\n",
    "    RUNNING_LOSS = 0.0\n",
    "    ACCURACY = 0.0\n",
    "\n",
    "    # model params\n",
    "    MODEL_NAME = 'yolo_nas_l' # choose from yolo_nas_s, yolo_nas_m, yolo_nas_l\n",
    "    PRETRAINED_WEIGHTS = 'coco' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class to load images and labels from separate folders\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_filenames = os.listdir(images_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_dir, self.image_filenames[idx])\n",
    "        label_name = os.path.join(self.labels_dir, self.image_filenames[idx] + '.txt')  # Assuming labels are in text files\n",
    "\n",
    "        print(label_name)\n",
    "\n",
    "        image = read_image(img_name)\n",
    "        \n",
    "        # Load and process the label file (adjust as needed based on your label file format)\n",
    "        with open(label_name, 'r') as label_file:\n",
    "            label = label_file.read().strip()\n",
    "            label = int(label)  # Assuming labels are integer values\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data transformation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create custom datasets for train, validation, and test\n",
    "train_dataset = CustomImageDataset(\n",
    "    images_dir=f'{config.DATA_DIR}\\\\{config.TRAIN_IMAGES_DIR}',\n",
    "    labels_dir=f'{config.DATA_DIR}\\\\{config.TRAIN_LABELS_DIR}',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = CustomImageDataset(\n",
    "    images_dir=f'{config.DATA_DIR}\\\\{config.VAL_IMAGES_DIR}',\n",
    "    labels_dir=f'{config.DATA_DIR}\\\\{config.VAL_LABELS_DIR}',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = CustomImageDataset(\n",
    "    images_dir=f'{config.DATA_DIR}\\\\{config.TEST_IMAGES_DIR}',\n",
    "    labels_dir=f'{config.DATA_DIR}\\\\{config.TEST_LABELS_DIR}',\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = f'{config.DATA_DIR}\\\\{config.TRAIN_IMAGES_DIR}'\n",
    "\n",
    "print(\"train_root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in c:\\Users\\mhajj\\Documents\\RUTILEA\\mhajjaj\\GearInspection-Dataset3\\CategoryNG\\ClassAll\\train\\images.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mhajj\\Documents\\RUTILEA\\mhajjaj\\GearConfusionMatrix.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create custom datasets for train, validation, and test\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m ImageFolder(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     root\u001b[39m=\u001b[39;49mtrain_root,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     transform\u001b[39m=\u001b[39;49mtransform\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m val_dataset \u001b[39m=\u001b[39m ImageFolder(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     root\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mVAL_IMAGES_DIR,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     transform\u001b[39m=\u001b[39mtransform\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m ImageFolder(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     root\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mTEST_IMAGES_DIR,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     transform\u001b[39m=\u001b[39mtransform\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mhajj/Documents/RUTILEA/mhajjaj/GearConfusionMatrix.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mhajj\\Documents\\RUTILEA\\rutilea\\lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    310\u001b[0m         root,\n\u001b[0;32m    311\u001b[0m         loader,\n\u001b[0;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    316\u001b[0m     )\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\mhajj\\Documents\\RUTILEA\\rutilea\\lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\mhajj\\Documents\\RUTILEA\\rutilea\\lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\Users\\mhajj\\Documents\\RUTILEA\\rutilea\\lib\\site-packages\\torchvision\\datasets\\folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     40\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in c:\\Users\\mhajj\\Documents\\RUTILEA\\mhajjaj\\GearInspection-Dataset3\\CategoryNG\\ClassAll\\train\\images."
     ]
    }
   ],
   "source": [
    "# Create custom datasets for train, validation, and test\n",
    "train_dataset = ImageFolder(\n",
    "    root=train_root,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = ImageFolder(\n",
    "    root=config.VAL_IMAGES_DIR,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = ImageFolder(\n",
    "    root=config.TEST_IMAGES_DIR,\n",
    "    transform=transform\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rutilea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
